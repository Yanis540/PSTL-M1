{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import platform\n",
    "import threading\n",
    "import jsonschema\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_INSTANCES_PATH='./dataset/correct-instances'\n",
    "if not os.path.exists(CORRECT_INSTANCES_PATH): \n",
    "    os.mkdir(CORRECT_INSTANCES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Edit distances General function calulcation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMAS_PATH = './dataset/schemas'\n",
    "MIGRATED_SCHEMAS_PATH = './dataset/schemas-migrated'\n",
    "CORRECT_INSTANCES_BRACKET_PATH = './dataset/bracket/correct-instances'\n",
    "EXPERIMENT_SCRIPT = './scripts/expr.sh'\n",
    "WITNESSES = ['DG','JE','JSF']\n",
    "WITNESSES_EDIT_DISTANCES_COLUMNS = [f'{x}_ted'for x in WITNESSES ]\n",
    "WITNESSES_DIRS = [f'./dataset/{x}'for x in WITNESSES ]\n",
    "WITNESSES_BRACKET_DIRS = [f'./dataset/bracket/{x}'for x in WITNESSES ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Initialize the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_results(columns,file_name):\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    if not os.path.exists('./results'):\n",
    "        os.makedirs('./results')\n",
    "    df.to_csv(f'./results/{file_name}.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(result_file_name,schema_name:str,results:list,columns:list):\n",
    "    df = pd.DataFrame([[schema_name]+results],columns=columns) \n",
    "    df.to_csv(f'./results/{result_file_name}.csv',mode='a',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def witness_file_name(schema_name,is_json_file=False):\n",
    "    return schema_name+'_witness.'+ ('json' if is_json_file else 'bracket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Calculating edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(schema_name:str,correct_instance_schema_bracket_path:str,w_bracket_dir)->int | None: \n",
    "    witness_bracket_path = f'{w_bracket_dir}/{witness_file_name(schema_name)}'\n",
    "    if not os.path.exists(witness_bracket_path) : \n",
    "        return None \n",
    "    # print(correct_instance_schema_bracket_path)\n",
    "    # print(witness_bracket_path)\n",
    "    if platform.system() == 'Windows':\n",
    "        command=['wsl',EXPERIMENT_SCRIPT,correct_instance_schema_bracket_path,witness_bracket_path]\n",
    "    else : \n",
    "        command = [EXPERIMENT_SCRIPT,correct_instance_schema_bracket_path,witness_bracket_path]\n",
    "    max_retries = 3\n",
    "    retry_delay = 1  # seconds\n",
    "    \n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            process = subprocess.run(command, capture_output=True, text=True, timeout=30)  # Increase or decrease timeout as needed\n",
    "            if process.returncode != 0:\n",
    "                # print(\"Subprocess failed:\", process.stderr)\n",
    "                continue\n",
    "            output_string = process.stdout.strip()\n",
    "            output_parts = output_string.split(':')\n",
    "            if len(output_parts) < 2:\n",
    "                # print(\"Unexpected output format. Expected 'TED Distances: <Number>'. Actual:\", output_string)\n",
    "                continue \n",
    "            result = int(float(output_parts[1]))\n",
    "            return result\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"Subprocess timed out on attempt {retry + 1}. Retrying...\")\n",
    "            # time.sleep(retry_delay)\n",
    "    \n",
    "    # print(\"Max retries exceeded. Unable to calculate edit distance.\")\n",
    "    return None\n",
    "  \n",
    "# print(calculate_edit_distance('o9915','./dataset/bracket/correct-instances/o9915.bracket','./dataset/bracket/JE/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Number of Errors and TED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "witnesses_number_errors_columns = [f'{x}_number_errors'for x in WITNESSES ]\n",
    "# AST node stuff \n",
    "witnesses_ast_sizes_columns = [f'{x}_ast_size'for x in WITNESSES ]\n",
    "ast_sizes_columns = ['correct_instance_ast_size']+witnesses_ast_sizes_columns\n",
    "ast_sizes_dirs = [CORRECT_INSTANCES_PATH]+WITNESSES_DIRS\n",
    "\n",
    "columns_ted_number_errors = ['schema']+ WITNESSES_EDIT_DISTANCES_COLUMNS+witnesses_number_errors_columns+ast_sizes_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Calculating the number of errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_number_errors(schema_name,witness_path):\n",
    "    with open(f'{SCHEMAS_PATH}/{schema_name}.json','r',encoding='utf-8') as f : \n",
    "        schema = json.load(f)\n",
    "    if not os.path.exists(witness_path):\n",
    "        return None \n",
    "    try : \n",
    "        with open(witness_path,'r',encoding='utf-8') as f : \n",
    "            data = json.load(f)\n",
    "    except :\n",
    "        return None\n",
    "    try : \n",
    "        validator = jsonschema.Draft7Validator(schema)\n",
    "        # print(list(validator.iter_errors(data)))\n",
    "        return len(list(validator.iter_errors(data)))\n",
    "    except Exception as e : \n",
    "        if(\"error: nothing to repeat at position 1\" in str(e)) : # error appearing somehow\n",
    "            return 0\n",
    "        else :\n",
    "            return None \n",
    "        \n",
    "    \n",
    "# calcualte_number_errors('o33194',f'./dataset/JE/{witness_file_name(\"o33194\",True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculate the number of nodes of a json schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_size_json(doc):\n",
    "    \"\"\"Returns the size of the corresponding tree of the given JSON.\"\"\"\n",
    "\n",
    "    size = 0\n",
    "    if isinstance(doc, dict): # OBJECT\n",
    "        # Count the node of the object and all its keys.\n",
    "        size += 1 + len(doc.keys())\n",
    "        # Add the sizes of all values.\n",
    "        for key, val in doc.items():\n",
    "            size += get_size_json(val)\n",
    "    elif isinstance(doc, list): # ARRAY\n",
    "        # Count the node of the array and all its array order nodes.\n",
    "        size += 1 + len(doc)\n",
    "        # Add the sizes of all values.\n",
    "        for val in doc:\n",
    "            size += get_size_json(val)\n",
    "    else: # VALUE\n",
    "        # Add node for the value.\n",
    "        size += 1\n",
    "    return size\n",
    "def calculate_ast_size(json_file_path:str):\n",
    "    try : \n",
    "        with open(json_file_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            tree_size  = get_size_json(data)\n",
    "        return tree_size \n",
    "    except :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_schema_edit_distance_number_errors_with_generators(result_file_name:str,schema:str,columns):\n",
    "    schema_name = schema.split('.')[0]\n",
    "    correct_instance_schema_bracket_path = f'{CORRECT_INSTANCES_BRACKET_PATH}/{schema_name}.bracket'\n",
    "    results = []\n",
    "    # calculate the edit distance \n",
    "    print(f\"Processing {schema_name}\")\n",
    "    print(\"Calculating edit distance : \")\n",
    "    for w_gen,w_bracket_dir in zip(WITNESSES,WITNESSES_BRACKET_DIRS): \n",
    "        # print(f\"\\t >{w_gen}\")\n",
    "        result = calculate_edit_distance(schema_name,correct_instance_schema_bracket_path,w_bracket_dir)\n",
    "        results.append(result)\n",
    "    # print(results)\n",
    "    if all([x== None for x in results]):\n",
    "        return \n",
    "    print(\"Calculating errors\")\n",
    "    # calculate the number of errors  \n",
    "    for w_gen,w_dir in zip(WITNESSES,WITNESSES_DIRS): \n",
    "        # print(f\"\\t >{w_gen}\")\n",
    "        w_path = f'{w_dir}/{witness_file_name(schema_name,True)}'\n",
    "        result = calcualte_number_errors(schema_name,w_path)\n",
    "        results.append(result)\n",
    "    \n",
    "    # calculate the number of ast \n",
    "    print(\"Caluculating number of ast nodes\")\n",
    "    for i,(instance_column_name,instance_base_dir) in enumerate(zip(ast_sizes_columns,ast_sizes_dirs)):\n",
    "        file_name = schema if i==0 else witness_file_name(schema_name,True)\n",
    "        json_instance_path = f'{instance_base_dir}/{file_name}'\n",
    "        result = calculate_ast_size(json_instance_path)\n",
    "        results.append(result)\n",
    "    \n",
    "    print(f\"Processed {schema_name}\")\n",
    "    save_results(result_file_name,schema_name,results,columns)\n",
    "    pass  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"ted_number_errors\"\n",
    "df_ted_number_errors=initialise_results(columns_ted_number_errors,result_file)\n",
    "for schema in tqdm(os.listdir(SCHEMAS_PATH)):\n",
    "    process_schema_edit_distance_number_errors_with_generators(result_file,schema,columns_ted_number_errors)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'128'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Distance TED:128\".split(':')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Type of errors vs TED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jschon import create_catalog,JSON, JSONSchema\n",
    "import json,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "witnesses_type_of_errors_columns = [f'{x}_type_of_errors'for x in WITNESSES ]\n",
    "columns_ted_type_of_errors = ['schema']+ witnesses_type_of_errors_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_catalog('2019-09')\n",
    "\n",
    "    \n",
    "    # print(\"there's still error\")\n",
    "   \n",
    "keywords_to_avoid = [\n",
    "    'not','anyOf','oneOf','allOf','properties','patternPropreties','items',\n",
    "    'additionalProperties','contains','unevaluatedProperties','prefixItems', 'unevaluatedItems'\n",
    "]\n",
    "def extract_errors_map(error:dict, error_map:dict):\n",
    "    # print(error)\n",
    "    # if there's errors in subschema treat them since they are the origin of the error  \n",
    "    keywordLocation = str(error['keywordLocation'])\n",
    "    key = keywordLocation.split('/')[-1]\n",
    "    if 'errors' in error:\n",
    "        if key in  keywords_to_avoid :\n",
    "            if error_map.get(key) is None : \n",
    "                error_map[key]=[error['error'] if 'error' in error else '']\n",
    "            else : \n",
    "                error_map[key].append(error['error'] if 'error' in error else '') \n",
    "        for e in error['errors']:\n",
    "            extract_errors_map(e, error_map)\n",
    "    else : \n",
    "        # if key not in keywords_to_avoid:\n",
    "        if error_map.get(key) is None : \n",
    "            error_map[key]=[error['error'] if 'error' in error else '']\n",
    "        else : \n",
    "            error_map[key].append(error['error'] if 'error' in error else '') \n",
    "    \n",
    "        \n",
    "def extract_errors(errors): \n",
    "    error_map= {}\n",
    "    for error in errors : \n",
    "        extract_errors_map(error,error_map)\n",
    "    return list(error_map.keys())\n",
    "def validate_instance(schema_dir:str,instance_dir): \n",
    "    with open(schema_dir,'r',encoding='utf-8') as f : \n",
    "        schema= json.load(f)\n",
    "    demo_schema = JSONSchema(schema)\n",
    "    # print(demo_schema)\n",
    "    with open (instance_dir,'r',encoding='utf-8') as f : \n",
    "        instance=json.load(f)\n",
    "        \n",
    "    result = demo_schema.evaluate(\n",
    "        JSON(instance)\n",
    "    )\n",
    "    return result \n",
    "def get_errors_validation(schema_dir:str,instance_dir:str): \n",
    "    try:\n",
    "        result = validate_instance(schema_dir,instance_dir)\n",
    "        # print(result.output('detailed'))# if errors in result.output('detailed')\n",
    "        if(result.output(\"detailed\")['valid']==False or \"errors\" in result.output(\"detailed\")): \n",
    "            errors = extract_errors(result.output('detailed')['errors'])\n",
    "        else : \n",
    "            errors=[]\n",
    "        return errors\n",
    "    except : \n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_schema_edit_distance_with_generators(result_file_name:str,schema:str,columns):\n",
    "    schema_name = schema.split('.')[0]\n",
    "    migrated_schema_path = f'{MIGRATED_SCHEMAS_PATH}/{schema}'\n",
    "    correct_instance_schema_bracket_path = f'{CORRECT_INSTANCES_BRACKET_PATH}/{schema_name}.bracket'\n",
    "    results = []\n",
    "    # calculate the edit distance \n",
    "    print(f\"Processing {schema_name}\")\n",
    "    print(\"Calculating errors\")\n",
    "    # calculate the number of errors  \n",
    "    for w_gen,w_dir in zip(WITNESSES,WITNESSES_DIRS): \n",
    "        print(f\"\\t >{w_gen}\")\n",
    "        w_path = f'{w_dir}/{witness_file_name(schema_name,is_json_file=True)}'\n",
    "        if not os.path.isfile(w_path) : \n",
    "            result = []\n",
    "        else : \n",
    "            result = get_errors_validation(migrated_schema_path,w_path)\n",
    "        results.append(result)\n",
    "    \n",
    "    print(f\"Processed {schema_name}\")\n",
    "    save_results(result_file_name,schema_name,results,columns)\n",
    "    pass  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_name=\"ted_type_of_errors\"\n",
    "df_ted_type_of_errors=initialise_results(columns_ted_type_of_errors,result_file_name)\n",
    "for schema in tqdm(os.listdir(MIGRATED_SCHEMAS_PATH)):\n",
    "    process_schema_edit_distance_with_generators(result_file_name,schema,columns_ted_type_of_errors)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
